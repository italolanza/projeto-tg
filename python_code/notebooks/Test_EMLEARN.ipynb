{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `emlearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import os\n",
    "import emlearn\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # When executed as regular .py script\n",
    "    os.environ[\"EMLEARN_INCLUDE_DIR\"] = emlearn.includedir\n",
    "    os.environ[\"LIBRARY_PATH\"] = emlearn.includedir\n",
    "    print(os.environ.get(\"LIBRARY_PATH\"))\n",
    "    here = os.path.dirname(__file__)\n",
    "    \n",
    "except NameError:\n",
    "    # When executed as Jupyter notebook / Sphinx Gallery\n",
    "    here = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset():\n",
    "    data = pd.read_csv(\"../data/extracted_features/features_like_artigo.csv\")\n",
    "    data = data.drop(columns=['Mean', 'Median']) # Remove the mean and median column\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_data():\n",
    "    data = pd.read_csv(\"../data/extracted_features/features_like_artigo.csv\")\n",
    "    X = data.iloc[:, 0:-1]                 # All column except the last one\n",
    "    X = X.drop(columns=['Mean', 'Median']) # Remove the mean and median column\n",
    "    y = data.iloc[:, -1]                   # Last Column\n",
    "\n",
    "    return X,y\n",
    "\n",
    "X_data, y_data = get_data()\n",
    "dataset = load_dataset()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "print(len(y_data))\n",
    "train, test  = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "print(len(test['FalutID']) + len(train['RMS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(out_dir, model_filename, test_data, test_predictions, feature_columns):\n",
    "    test_res = numpy.array(test_predictions).flatten()\n",
    "\n",
    "    test_dataset = \"\\n\".join([\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_data\", dtype='float', values=test_data),\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_results\", dtype='int', values=test_res),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_features', val=len(feature_columns)),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_samples', val=len(test_predictions)),\n",
    "    ])\n",
    "\n",
    "    test_code = test_dataset + \\\n",
    "    f'''\n",
    "    #include \"{model_filename}\" // emlearn generated model\n",
    "\n",
    "    #include <stdio.h> // printf\n",
    "\n",
    "    int\n",
    "    {name}_test() {{\n",
    "        const int n_features = {name}_testset_features;\n",
    "        const int n_testcases = {name}_testset_samples;\n",
    "\n",
    "        int errors = 0;\n",
    "\n",
    "        for (int i=0; i<n_testcases; i++) {{\n",
    "            const float *features = {name}_testset_data + (i*n_features);\n",
    "            const int expect_result = {name}_testset_results[i*1];\n",
    "\n",
    "            const int32_t out = model_predict(features, n_features);\n",
    "\n",
    "            if (out != expect_result) {{\n",
    "                printf(\\\"test-fail sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "                errors += 1;\n",
    "            }}\n",
    "            printf(\\\"test sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "\n",
    "        }}\n",
    "        return errors;\n",
    "    }}\n",
    "\n",
    "    int\n",
    "    main(int argc, const char *argv[])\n",
    "    {{\n",
    "        const int errors = {name}_test();\n",
    "        printf(\\\"Errors: %d \\\\n\\\", errors);\n",
    "        return errors;\n",
    "    }}'''\n",
    "\n",
    "    test_source_file = os.path.join(out_dir, f'test_{name}.c')\n",
    "    with open(test_source_file, 'w') as f:\n",
    "        f.write(test_code)\n",
    "\n",
    "    print('Generated', test_source_file)\n",
    "    print(f\"Outdir: {out_dir}\")\n",
    "    include_dirs = [ emlearn.common.get_include_dir() ]\n",
    "    test_executable = emlearn.common.compile_executable(\n",
    "            test_source_file,\n",
    "            out_dir,\n",
    "            name=f'test_{name}',\n",
    "            include_dirs=include_dirs\n",
    "    )\n",
    "\n",
    "    import subprocess\n",
    "    errors = None\n",
    "    try:\n",
    "        print(\"TRY\")\n",
    "        subprocess.check_output(test_executable)\n",
    "        errors = 0\n",
    "        print(\"ERROR\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        errors = e.returncode\n",
    "        print(f\"CATCH {e.returncode}\")\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(ax, model, X, y):\n",
    "    from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "    # show classification boundaries\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        model, X, alpha=0.4, ax=ax, response_method=\"auto\",\n",
    "    )\n",
    "\n",
    "    # show datapoints\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, s=20, edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, convert and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_run_classifier(model, name):\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.metrics import get_scorer\n",
    "\n",
    "    feature_columns = ['RMS','Variance','Skewness','Kurtosis', 'CrestFactor','ShapeFactor','ImpulseFactor','MarginFactor', 'Peak1','Peak2','Peak3','PeakLocs1','PeakLocs2','PeakLocs3']\n",
    "    feature_columns_plt = ['RMS','Variance']\n",
    "    target_column = \"FalutID\"\n",
    "\n",
    "    # Train model\n",
    "    train, test = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "    feature_columns = list(set(dataset.columns) - set([target_column]))\n",
    "    \n",
    "    # Realizar a validação cruzada com k = 5\n",
    "    # skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    # cv_scores = cross_val_score(model, X_data, y_data, cv=skf)\n",
    "\n",
    "    # limit to 2 columns to be able to visualize\n",
    "    #feature_columns = ['total_phenols', 'color_intensity']\n",
    "    #feature_columns = ['alcohol', 'flavanoids']\n",
    "\n",
    "    print(f\"Len test[feature_columns]: {len(test['RMS'])}\")\n",
    "    print(f'Len test[target_column]: {len(test[target_column])}')\n",
    "\n",
    "    model.fit(train[feature_columns], train[target_column])\n",
    "    accuracy = get_scorer('accuracy')(model, test[feature_columns], test[target_column])\n",
    "\n",
    "    # Convert model\n",
    "    out_dir = os.path.join(here, 'classifiers')\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    model_filename = os.path.join(out_dir, f'{name}_model.h')\n",
    "    \n",
    "    print(f\"Converting {name} model...\")\n",
    "    cmodel = emlearn.convert(model)\n",
    "    \n",
    "    print(f\"Saving {name} model to file {model_filename}....\")\n",
    "    code = cmodel.save(file=model_filename, name='model')\n",
    "    print(f\"Model {name} saved!\")\n",
    "\n",
    "\n",
    "    # Test converted model\n",
    "    # test_pred = cmodel.predict(test[feature_columns].values)\n",
    "    test_pred = test[target_column] -1\n",
    "    test_pred = test_pred\n",
    "    print(type(test_pred))\n",
    "    \n",
    "    # Generate a test dataset\n",
    "    test_data = numpy.array(test[feature_columns]).flatten()\n",
    "    print(type(test_data))\n",
    "    # test_data = test[feature_columns].values\n",
    "\n",
    "    errors = check_correctness(out_dir, model_filename, test_data, test_pred, feature_columns)\n",
    "        \n",
    "    print(f\"Tested {name}: {errors} errors  {1 - (errors/len(test[target_column]))}\")\n",
    "    print(f\"Tested {name} - accuracy: {accuracy}\")\n",
    "\n",
    "    #plot_results(ax, model, X_data[feature_columns_plt], y_data[target_column])\n",
    "    #plot_results(ax, model, test[feature_columns], test[target_column])\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC, SVR\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# classifiers = {\n",
    "#     'bagging_tree': BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42),\n",
    "#     'quadratic_svm': SVC(kernel='poly', degree=2, C=2),\n",
    "#     'decision_tree': DecisionTreeClassifier(),\n",
    "#     'gaussian_naive_bayes': GaussianNB(),\n",
    "#     'knn_classifier': KNeighborsClassifier(n_neighbors=5),\n",
    "#     'sklearn_mlp': MLPClassifier(hidden_layer_sizes=(10,10,), max_iter=1000, random_state=42),\n",
    "# }\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.tree\n",
    "import sklearn.neural_network\n",
    "import sklearn.naive_bayes\n",
    "\n",
    "classifiers = {\n",
    "    'decision_tree': sklearn.tree.DecisionTreeClassifier(),\n",
    "    'random_forest': sklearn.ensemble.RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'extra_trees': sklearn.ensemble.ExtraTreesClassifier(n_estimators=10, random_state=42),\n",
    "    'gaussian_naive_bayes': sklearn.naive_bayes.GaussianNB(),\n",
    "    # 'sklearn_mlp': sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(10,10,), max_iter=1000, random_state=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, cls) in classifiers.items():\n",
    "    print(f'Training {name}')\n",
    "    build_run_classifier(cls, name)\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel TG",
   "language": "python",
   "name": "projeto-tg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
