{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Faz o treinamento e avaliacao da acuracia dos classificadores utilizando um arquivo `.csv` gerado pelo notebook `Main.ipynb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import emlearn\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv(\"../data/extracted_features/features_like_artigo.csv\")\n",
    "X = data.iloc[:, 0:-1]                # All column except the last one\n",
    "X = X.drop(columns=['Mean', 'Median']) # Remove the mean and median column\n",
    "y = data.iloc[:, -1]                  # Last Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Desktop Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Treinamento indireto dos modelos semelhantes ao do artigo utilizando a funcionalidade do sklearn `cross_val_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Trees Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o classificador base (uma única árvore de decisão)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Criar o classificador Bagged Trees Ensemble\n",
    "bagged_classifier = BaggingClassifier(estimator=base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "bgtree_scores = cross_val_score(bagged_classifier, X, y, cv=skf)\n",
    "\n",
    "print(\"Acurácia em cada fold :\", bgtree_scores)\n",
    "print(\"Acurácia média        :\", bgtree_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o classificador SVM Quadrático\n",
    "svm_classifier = SVC(kernel='poly',degree=2,C=2)  # degree=2 para o kernel quadrático\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "svm_cv_scores = cross_val_score(svm_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", svm_cv_scores)\n",
    "print(\"Acurácia média        :\", svm_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o classificador Fine Decision Tree\n",
    "fine_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "fdtree_cv_scores = cross_val_score(fine_tree_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", fdtree_cv_scores)\n",
    "print(\"Acurácia média        :\", fdtree_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o classificador Naïve Bayes\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "nb_cv_scores = cross_val_score(naive_bayes_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", nb_cv_scores)\n",
    "print(\"Acurácia média        :\", nb_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o classificador KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)  # Número de vizinhos = 3 (pode ser ajustado)\n",
    "\n",
    "# # Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "knn_cv_scores = cross_val_score(knn_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", knn_cv_scores)\n",
    "print(\"Acurácia média        :\", knn_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo\n",
    "print(f\"Bagged Trees Ensemble: {bgtree_scores.mean()}\")\n",
    "print(f\"Quadratic SVM:         {svm_cv_scores.mean()}\")\n",
    "print(f\"Fine Decision Tree :   {fdtree_cv_scores.mean()}\")\n",
    "print(f\"Naïve Bayes :          {nb_cv_scores.mean()}\")\n",
    "print(f\"KNeighbors (KNN) :     {knn_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MCU Classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emlearn\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import get_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['RMS','Variance','Skewness','Kurtosis','CrestFactor','ShapeFactor','ImpulseFactor','MarginFactor','Peak1','Peak2','Peak3','PeakLocs1','PeakLocs2','PeakLocs3']\n",
    "feature_columns_plt = ['Mean', 'Median']\n",
    "target_column = \"FaultID\" # ta errado porque no csv eu gerei com o nome errado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42, stratify=data['FaultID'])\n",
    "feature_columns = list(set(data.columns) - set([target_column]))\n",
    "#test_test[\"FaultID\"].value_counts() / len(test_set[\"FaultID\"]) # checking classes distribution\n",
    "#train_set[\"FaultID\"].value_counts() / len(train_set[\"FaultID\"]) # checking classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_emlearn = {\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'extra_trees': ExtraTreesClassifier(n_estimators=10, random_state=42),\n",
    "    'gaussian_naive_bayes': GaussianNB(),\n",
    "    'knn' : KNeighborsClassifier(n_neighbors=3)\n",
    "    # 'sklearn_mlp': sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(10,10,), max_iter=1000, random_state=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(out_dir, model_filename, test_data, test_predictions, feature_columns):\n",
    "    test_res = np.array(test_predictions).flatten()\n",
    "\n",
    "    test_dataset = \"\\n\".join([\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_data\", dtype='float', values=test_data),\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_results\", dtype='int', values=test_res),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_features', val=len(feature_columns)),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_samples', val=len(test_predictions)),\n",
    "    ])\n",
    "\n",
    "    test_code = test_dataset + \\\n",
    "    f'''\n",
    "    #include \"{model_filename}\" // emlearn generated model\n",
    "\n",
    "    #include <stdio.h> // printf\n",
    "\n",
    "    int\n",
    "    {name}_test() {{\n",
    "        const int n_features = {name}_testset_features;\n",
    "        const int n_testcases = {name}_testset_samples;\n",
    "\n",
    "        int errors = 0;\n",
    "\n",
    "        for (int i=0; i<n_testcases; i++) {{\n",
    "            const float *features = {name}_testset_data + (i*n_features);\n",
    "            const int expect_result = {name}_testset_results[i*1];\n",
    "\n",
    "            const int32_t out = model_predict(features, n_features);\n",
    "\n",
    "            if (out != expect_result) {{\n",
    "                printf(\\\"test-fail sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "                errors += 1;\n",
    "            }}\n",
    "            printf(\\\"test sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "\n",
    "        }}\n",
    "        return errors;\n",
    "    }}\n",
    "\n",
    "    int\n",
    "    main(int argc, const char *argv[])\n",
    "    {{\n",
    "        const int errors = {name}_test();\n",
    "        printf(\\\"Errors: %d \\\\n\\\", errors);\n",
    "        return errors;\n",
    "    }}'''\n",
    "\n",
    "    test_source_file = os.path.join(out_dir, f'test_{name}.c')\n",
    "    with open(test_source_file, 'w') as f:\n",
    "        f.write(test_code)\n",
    "\n",
    "    print('Generated', test_source_file)\n",
    "    print(f\"Outdir: {out_dir}\")\n",
    "    include_dirs = [ emlearn.common.get_include_dir() ]\n",
    "    test_executable = emlearn.common.compile_executable(\n",
    "            test_source_file,\n",
    "            out_dir,\n",
    "            name=f'test_{name}',\n",
    "            include_dirs=include_dirs\n",
    "    )\n",
    "\n",
    "    import subprocess\n",
    "    errors = None\n",
    "    try:\n",
    "        print(\"TRY\")\n",
    "        subprocess.check_output(test_executable)\n",
    "        errors = 0\n",
    "        print(\"ERROR\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        errors = e.returncode\n",
    "        print(f\"CATCH {e.returncode}\")\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(ax, model, X, y):\n",
    "    from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "    # show classification boundaries\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        model, X, alpha=0.4, ax=ax, response_method=\"auto\",\n",
    "    )\n",
    "\n",
    "    # show datapoints\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, s=20, edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_run_classifier(model, name, train, test):\n",
    "\n",
    "    X_data = X\n",
    "    y_data = y\n",
    "\n",
    "    # Realizar a validação cruzada com k = 5\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    cv_scores = cross_val_score(model, X_data, y_data, cv=skf)\n",
    "    print(f\"{name} - CV_SCORE : {cv_scores.mean()}\")\n",
    "\n",
    "    print(f\"Len test[feature_columns]: {len(test['RMS'])}\")\n",
    "    print(f'Len test[target_column]: {len(test[target_column])}')\n",
    "\n",
    "    # Train model\n",
    "    model.fit(train[feature_columns], train[target_column])\n",
    "    accuracy = get_scorer('accuracy')(model, test[feature_columns], test[target_column])\n",
    "\n",
    "    # Convert model\n",
    "    out_dir = os.path.join(os.getcwd(), '../data/c_models')\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    model_filename = os.path.join(out_dir, f'{name}_model.h')\n",
    "\n",
    "    print(f\"Converting {name} model...\")\n",
    "    cmodel = emlearn.convert(model, dtype='float')\n",
    "\n",
    "    print(f\"Saving {name} model to file {model_filename}....\")\n",
    "    code = cmodel.save(file=model_filename, name='model')\n",
    "    print(f\"Model {name} saved!\")\n",
    "\n",
    "\n",
    "    # Test converted model\n",
    "    # test_pred = cmodel.predict(test[feature_columns].values)\n",
    "    test_pred = test[target_column] -1\n",
    "    test_pred = test_pred\n",
    "    print(type(test_pred))\n",
    "\n",
    "    # Generate a test dataset\n",
    "    test_data = np.array(test[feature_columns]).flatten()\n",
    "    print(type(test_data))\n",
    "    # test_data = test[feature_columns].values\n",
    "\n",
    "    # errors = check_correctness(out_dir, model_filename, test_data, test_pred, feature_columns)\n",
    "\n",
    "    # print(f\"Tested {name}: {errors} errors  {1 - (errors/len(test[target_column]))}\")\n",
    "    print(f\"Tested {name} - accuracy: {accuracy}\")\n",
    "\n",
    "    # plot_results(ax, model, X_data[feature_columns_plt], y_data[target_column])\n",
    "    # plot_results(ax, model, test[feature_columns], test[target_column])\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, cls) in classifiers_emlearn.items():\n",
    "    print(f'Training {name}')\n",
    "    build_run_classifier(cls, name, train_set, test_set)\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel TG",
   "language": "python",
   "name": "projeto-tg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
