{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Faz o treinamento e avaliacao da acuracia dos classificadores utilizando um arquivo `.csv` gerado pelo notebook `Main.ipynb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import emlearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treinamento e teste foram embaralhados com sucesso.\n",
      "Dados de treinamento carregados: 5632 amostras\n",
      "Dados de teste carregados: 1431 amostras\n"
     ]
    }
   ],
   "source": [
    "# Carregar os dados de treinamento\n",
    "try:\n",
    "    training_data = pd.read_csv(\"../data/extracted_features/extracted_features_like_artigo_training.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo de treinamento não encontrado. Crie um CSV de exemplo.\")\n",
    "    # Criando um DataFrame de exemplo para o código poder ser executado\n",
    "    training_data = pd.DataFrame(np.random.rand(100, 15), columns=[f'feature_{i}' for i in range(14)] + ['FaultID'])\n",
    "    training_data['FaultID'] = np.random.randint(low=0, high=5, size=100)\n",
    "\n",
    "\n",
    "# Carregar os dados de teste\n",
    "try:\n",
    "    testing_data = pd.read_csv(\"../data/extracted_features/extracted_features_like_artigo_validation.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo de teste não encontrado. Crie um CSV de exemplo.\")\n",
    "    # Criando um DataFrame de exemplo para o código poder ser executado\n",
    "    testing_data = pd.DataFrame(np.random.rand(100, 15), columns=[f'feature_{i}' for i in range(14)] + ['FaultID'])\n",
    "    testing_data['FaultID'] = np.random.randint(low=0, high=5, size=100)\n",
    "\n",
    "\n",
    "# Definindo as colunas de features e o rótulo\n",
    "# Ajuste os nomes das colunas conforme o seu arquivo CSV\n",
    "feature_columns = ['RMS','Variance','Skewness','Kurtosis','CrestFactor','ShapeFactor','ImpulseFactor','MarginFactor','Peak1','Peak2','Peak3','PeakLocs1','PeakLocs2','PeakLocs3']\n",
    "target_column = \"FaultID\"\n",
    "\n",
    "# --- Embaralhar (shuffle) os dados ---\n",
    "# O random_state=42 garante que o embaralhamento seja sempre o mesmo, para resultados reproduzíveis.\n",
    "training_data = training_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "testing_data = testing_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Dados de treinamento e teste foram embaralhados com sucesso.\")\n",
    "\n",
    "# Preparar os conjuntos de dados\n",
    "X_train = training_data[feature_columns].astype('float32')\n",
    "Y_train = training_data[target_column]\n",
    "\n",
    "X_test = testing_data[feature_columns].astype('float32')\n",
    "Y_test = testing_data[target_column]\n",
    "\n",
    "print(f\"Dados de treinamento carregados: {X_train.shape[0]} amostras\")\n",
    "print(f\"Dados de teste carregados: {X_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Desktop Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Treinamento indireto dos modelos semelhantes ao do artigo utilizando a funcionalidade do sklearn `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avaliação dos Modelos de Desktop ---\n",
      "Acurácia do Bagged Trees Ensemble: 0.9783\n",
      "Acurácia do Quadratic SVM: 0.6946\n",
      "Acurácia do Fine Decision Tree: 0.9706\n",
      "Acurácia do Gaussian Naive Bayes: 0.8931\n",
      "Acurácia do K-Nearest Neighbors (KNN): 0.9245\n"
     ]
    }
   ],
   "source": [
    "# Dicionário com os classificadores para desktop\n",
    "desktop_classifiers = {\n",
    "    \"Bagged Trees Ensemble\": BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42),\n",
    "    \"Quadratic SVM\": SVC(kernel='poly', degree=2, C=2),\n",
    "    \"Fine Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "print(\"--- Avaliação dos Modelos de Desktop ---\")\n",
    "\n",
    "# Treinar e avaliar cada classificador\n",
    "results = {}\n",
    "for name, model in desktop_classifiers.items():\n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Fazer predições no conjunto de teste\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calcular a acurácia\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    results[name] = accuracy\n",
    "    print(f\"Acurácia do {name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MCU Classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_emlearn = {\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'extra_trees': ExtraTreesClassifier(n_estimators=10, random_state=42),\n",
    "    'gaussian_naive_bayes': GaussianNB(),\n",
    "    # 'knn' : KNeighborsClassifier(n_neighbors=3),\n",
    "    # 'sklearn_mlp': sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(10,10,), max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(out_dir, name, model_filename, test_data, test_predictions, feature_columns):\n",
    "    test_res = np.array(test_predictions).flatten()\n",
    "\n",
    "    test_dataset = \"\\n\".join([\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_data\", dtype='float', values=test_data),\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_results\", dtype='int', values=test_res),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_features', val=len(feature_columns)),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_samples', val=len(test_predictions)),\n",
    "    ])\n",
    "\n",
    "    test_code = test_dataset + \\\n",
    "    f'''\n",
    "    #include \"{model_filename}\" // emlearn generated model\n",
    "\n",
    "    #include <stdio.h> // printf\n",
    "\n",
    "    int {name}_test() {{\n",
    "        const int n_features = {name}_testset_features;\n",
    "        const int n_testcases = {name}_testset_samples;\n",
    "\n",
    "        int errors = 0;\n",
    "\n",
    "        for (int i=0; i<n_testcases; i++) {{\n",
    "            const float *features = {name}_testset_data + (i*n_features);\n",
    "            const int expect_result = {name}_testset_results[i*1];\n",
    "\n",
    "            const int out = model_predict(features, n_features);\n",
    "\n",
    "            if (out != expect_result) {{\n",
    "                printf(\\\"test-fail sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "                errors += 1;\n",
    "            }}\n",
    "            printf(\\\"test sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "\n",
    "        }}\n",
    "        return errors;\n",
    "    }}\n",
    "\n",
    "    int main(int argc, const char *argv[])\n",
    "    {{\n",
    "        const int errors = {name}_test();\n",
    "        printf(\\\"Errors: %d \\\\n\\\", errors);\n",
    "        return errors;\n",
    "    }}\n",
    "    '''\n",
    "\n",
    "    test_source_file = os.path.join(out_dir, f'test_{name}.c')\n",
    "    with open(test_source_file, 'w') as f:\n",
    "        f.write(test_code)\n",
    "\n",
    "    print('Generated', test_source_file)\n",
    "    print(f\"Outdir: {out_dir}\")\n",
    "    include_dirs = [ emlearn.common.get_include_dir() ]\n",
    "    test_executable = emlearn.common.compile_executable(\n",
    "            test_source_file,\n",
    "            out_dir,\n",
    "            name=f'test_{name}',\n",
    "            include_dirs=include_dirs\n",
    "    )\n",
    "\n",
    "    import subprocess\n",
    "    errors = None\n",
    "    try:\n",
    "        print(\"TRY\")\n",
    "        subprocess.check_output(test_executable)\n",
    "        errors = 0\n",
    "        print(\"ERROR\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        errors = e.returncode\n",
    "        print(f\"CATCH {e.returncode}\")\n",
    "\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(ax, model, X, y):\n",
    "    from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "    # show classification boundaries\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        model, X, alpha=0.4, ax=ax, response_method=\"auto\",\n",
    "    )\n",
    "\n",
    "    # show datapoints\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, s=20, edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_run_classifier(model, name, X_train, Y_train, X_test, Y_test, feature_columns):\n",
    "    \"\"\"\n",
    "    Treina, avalia, converte e salva um classificador usando emlearn.\n",
    "    \"\"\"\n",
    "    print(f\"Processando o modelo: {name}\")\n",
    "\n",
    "    # Treina o modelo com o conjunto de treinamento\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Avalia a acurácia no conjunto de teste\n",
    "    accuracy = accuracy_score(Y_test, model.predict(X_test))\n",
    "    print(f\"Acurácia do modelo em Python: {accuracy:.4f}\")\n",
    "\n",
    "    # Converte o modelo treinado para código C\n",
    "    inference_strategy = 'loadable'\n",
    "    if type(model).__name__ in emlearn.trees.SUPPORTED_ESTIMATORS:\n",
    "        inference_strategy = 'inline'\n",
    "\n",
    "    cmodel = emlearn.convert(\n",
    "        model,\n",
    "        method=inference_strategy,\n",
    "        dtype='float'\n",
    "    )\n",
    "\n",
    "    # Salva o modelo C em um arquivo .h\n",
    "    out_dir = os.path.join(os.getcwd(), '../data/c_models')\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    model_filename = os.path.join(out_dir, f'{name}_model.h')\n",
    "    \n",
    "    try:\n",
    "        cmodel.save(file=model_filename, name='model')\n",
    "        print(f\"Modelo salvo em: {model_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o modelo {name}: {e}\")\n",
    "\n",
    "    # Verifica a acurácia do modelo convertido\n",
    "    test_data_c = X_test.values.astype(np.float32)\n",
    "    c_predictions = cmodel.predict(test_data_c)\n",
    "    c_accuracy = accuracy_score(Y_test, c_predictions)\n",
    "    print(f\"Acurácia do modelo em C (emlearn): {c_accuracy:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'python_accuracy': accuracy,\n",
    "        'c_accuracy': c_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Treinamento e Conversão dos Modelos para MCU ---\n",
      "Processando o modelo: decision_tree\n",
      "Acurácia do modelo em Python: 0.9713\n",
      "Modelo salvo em: /home/italolanza/Workspace/projeto-tg/python_code/notebooks/../data/c_models/decision_tree_model.h\n",
      "Acurácia do modelo em C (emlearn): 0.9720\n",
      "----------------------------------------------------------------\n",
      "Processando o modelo: random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp/myinlinetree_proba.c: In function ‘classify_proba’:\n",
      "tmp/myinlinetree_proba.c:9:28: warning: unused variable ‘err’ [-Wunused-variable]\n",
      "    9 |             const EmlError err = eml_trees_predict_proba(&myinlinetree, values, length, outputs, N_CLASSES);\n",
      "      |                            ^~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo em Python: 0.9804\n",
      "Modelo salvo em: /home/italolanza/Workspace/projeto-tg/python_code/notebooks/../data/c_models/random_forest_model.h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp/myinlinetree_proba.c: In function ‘classify_proba’:\n",
      "tmp/myinlinetree_proba.c:9:28: warning: unused variable ‘err’ [-Wunused-variable]\n",
      "    9 |             const EmlError err = eml_trees_predict_proba(&myinlinetree, values, length, outputs, N_CLASSES);\n",
      "      |                            ^~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo em C (emlearn): 0.9804\n",
      "----------------------------------------------------------------\n",
      "Processando o modelo: extra_trees\n",
      "Acurácia do modelo em Python: 0.9804\n",
      "Modelo salvo em: /home/italolanza/Workspace/projeto-tg/python_code/notebooks/../data/c_models/extra_trees_model.h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp/myinlinetree_proba.c: In function ‘classify_proba’:\n",
      "tmp/myinlinetree_proba.c:9:28: warning: unused variable ‘err’ [-Wunused-variable]\n",
      "    9 |             const EmlError err = eml_trees_predict_proba(&myinlinetree, values, length, outputs, N_CLASSES);\n",
      "      |                            ^~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo em C (emlearn): 0.9804\n",
      "----------------------------------------------------------------\n",
      "Processando o modelo: gaussian_naive_bayes\n",
      "Acurácia do modelo em Python: 0.8931\n",
      "Modelo salvo em: /home/italolanza/Workspace/projeto-tg/python_code/notebooks/../data/c_models/gaussian_naive_bayes_model.h\n",
      "Acurácia do modelo em C (emlearn): 0.7897\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dicionário com os classificadores para emlearn\n",
    "classifiers_emlearn = {\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=42),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'extra_trees': ExtraTreesClassifier(n_estimators=10, random_state=42),\n",
    "    'gaussian_naive_bayes': GaussianNB(),\n",
    "}\n",
    "\n",
    "print(\"\\n--- Treinamento e Conversão dos Modelos para MCU ---\")\n",
    "\n",
    "mcu_results = {}\n",
    "for name, model in classifiers_emlearn.items():\n",
    "    result = build_run_classifier(model, name, X_train, Y_train, X_test, Y_test, feature_columns)\n",
    "    mcu_results[name] = result\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESUMO FINAL DAS ACURÁCIAS =====\n",
      "\n",
      "--- Modelos de Desktop ---\n",
      "Bagged Trees Ensemble     | Acurácia: 0.9783\n",
      "Quadratic SVM             | Acurácia: 0.6946\n",
      "Fine Decision Tree        | Acurácia: 0.9706\n",
      "Gaussian Naive Bayes      | Acurácia: 0.8931\n",
      "K-Nearest Neighbors (KNN) | Acurácia: 0.9245\n",
      "\n",
      "--- Modelos para MCU (Python vs C) ---\n",
      "decision_tree             | Acurácia Python: 0.9713 | Acurácia C: 0.9720\n",
      "random_forest             | Acurácia Python: 0.9804 | Acurácia C: 0.9804\n",
      "extra_trees               | Acurácia Python: 0.9804 | Acurácia C: 0.9804\n",
      "gaussian_naive_bayes      | Acurácia Python: 0.8931 | Acurácia C: 0.7897\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== RESUMO FINAL DAS ACURÁCIAS =====\\n\")\n",
    "print(\"--- Modelos de Desktop ---\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name:<25} | Acurácia: {acc:.4f}\")\n",
    "\n",
    "print(\"\\n--- Modelos para MCU (Python vs C) ---\")\n",
    "for name, res in mcu_results.items():\n",
    "    print(f\"{name:<25} | Acurácia Python: {res['python_accuracy']:.4f} | Acurácia C: {res['c_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto-tg-ZGfju8ng-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
