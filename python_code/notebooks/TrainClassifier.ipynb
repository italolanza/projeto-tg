{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Faz o treinamento e avaliacao da acuracia dos classificadores utilizando um arquivo `.csv` gerado pelo notebook `FeatureExtractor.ipynb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import emlearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de treinamento\n",
    "try:\n",
    "    training_data = pd.read_csv(\"../data/extracted_features/extracted_features_training.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo de treinamento não encontrado. Crie um CSV de exemplo.\")\n",
    "    # Criando um DataFrame de exemplo para o código poder ser executado\n",
    "    training_data = pd.DataFrame(np.random.rand(100, 15), columns=[f'feature_{i}' for i in range(14)] + ['FaultID'])\n",
    "    training_data['FaultID'] = np.random.randint(low=0, high=5, size=100)\n",
    "\n",
    "\n",
    "# Carregar os dados de teste\n",
    "try:\n",
    "    testing_data = pd.read_csv(\"../data/extracted_features/extracted_features_validation.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo de teste não encontrado. Crie um CSV de exemplo.\")\n",
    "    # Criando um DataFrame de exemplo para o código poder ser executado\n",
    "    testing_data = pd.DataFrame(np.random.rand(100, 15), columns=[f'feature_{i}' for i in range(14)] + ['FaultID'])\n",
    "    testing_data['FaultID'] = np.random.randint(low=0, high=5, size=100)\n",
    "\n",
    "\n",
    "# Combinar dados de treino e teste para Cross-Validation ---\n",
    "full_data = pd.concat([training_data, testing_data], ignore_index=True)\n",
    "\n",
    "# Definindo as colunas de features e o rótulo\n",
    "# Ajuste os nomes das colunas conforme o seu arquivo CSV\n",
    "feature_columns = ['RMS','Variance','Skewness','Kurtosis','CrestFactor','ShapeFactor','ImpulseFactor','MarginFactor','Peak1','Peak2','Peak3','PeakLocs1','PeakLocs2','PeakLocs3']\n",
    "target_column = \"FaultID\"\n",
    "\n",
    "# Preparar o conjunto de dados completo para cross-validation\n",
    "X_full = full_data[feature_columns].astype('float32')\n",
    "Y_full = full_data[target_column]\n",
    "\n",
    "# Dados de treino/teste originais para a geração do modelo final em C\n",
    "X_train = training_data[feature_columns].astype('float32')\n",
    "Y_train = training_data[target_column]\n",
    "X_test = testing_data[feature_columns].astype('float32')\n",
    "Y_test = testing_data[target_column]\n",
    "\n",
    "\n",
    "print(f\"Dados totais para cross-validation: {X_full.shape[0]} amostras\")\n",
    "print(f\"Dados de treinamento para modelo final: {X_train.shape[0]} amostras\")\n",
    "print(f\"Dados de teste para modelo final: {X_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Desktop Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Treinamento indireto dos modelos semelhantes ao do artigo utilizando a funcionalidade do sklearn `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário com os classificadores para desktop\n",
    "desktop_classifiers = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Bagged Trees Ensemble\": BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42),\n",
    "    \"Random Florest\": RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    \"Quadratic SVM\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='poly', degree=2, C=2)),\n",
    "    ]),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "print(\"--- Avaliação dos Modelos de Desktop com Cross-Validation (k=5) ---\")\n",
    "\n",
    "# Treinar e avaliar cada classificador usando validação cruzada\n",
    "results_cv = {}\n",
    "for name, model in desktop_classifiers.items():\n",
    "    # Realiza a validação cruzada com k=5\n",
    "    # A função retorna um array com a acurácia de cada fold\n",
    "    scores = cross_val_score(model, X_full, Y_full, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Armazena a média e o desvio padrão dos scores\n",
    "    results_cv[name] = {'mean_accuracy': scores.mean(), 'std_accuracy': scores.std()}\n",
    "    \n",
    "    print(f\"Acurácia do {name}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MCU Classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(out_dir, name, model_filename, test_data, test_predictions, feature_columns):\n",
    "    test_res = np.array(test_predictions).flatten()\n",
    "\n",
    "    test_dataset = \"\\n\".join([\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_data\", dtype='float', values=test_data),\n",
    "        emlearn.cgen.array_declare(f\"{name}_testset_results\", dtype='int', values=test_res),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_features', val=len(feature_columns)),\n",
    "        emlearn.cgen.constant_declare(f'{name}_testset_samples', val=len(test_predictions)),\n",
    "    ])\n",
    "\n",
    "    test_code = test_dataset + \\\n",
    "    f'''\n",
    "    #include \"{model_filename}\" // emlearn generated model\n",
    "\n",
    "    #include <stdio.h> // printf\n",
    "\n",
    "    int {name}_test() {{\n",
    "        const int n_features = {name}_testset_features;\n",
    "        const int n_testcases = {name}_testset_samples;\n",
    "\n",
    "        int errors = 0;\n",
    "\n",
    "        for (int i=0; i<n_testcases; i++) {{\n",
    "            const float *features = {name}_testset_data + (i*n_features);\n",
    "            const int expect_result = {name}_testset_results[i*1];\n",
    "\n",
    "            const int out = model_predict(features, n_features);\n",
    "\n",
    "            if (out != expect_result) {{\n",
    "                printf(\\\"test-fail sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "                errors += 1;\n",
    "            }}\n",
    "            printf(\\\"test sample=%d expect=%d got=%d \\\\n\\\", i, expect_result, out);\n",
    "\n",
    "        }}\n",
    "        return errors;\n",
    "    }}\n",
    "\n",
    "    int main(int argc, const char *argv[])\n",
    "    {{\n",
    "        const int errors = {name}_test();\n",
    "        printf(\\\"Errors: %d \\\\n\\\", errors);\n",
    "        return errors;\n",
    "    }}\n",
    "    '''\n",
    "\n",
    "    test_source_file = os.path.join(out_dir, f'test_{name}.c')\n",
    "    with open(test_source_file, 'w') as f:\n",
    "        f.write(test_code)\n",
    "\n",
    "    print('Generated', test_source_file)\n",
    "    print(f\"Outdir: {out_dir}\")\n",
    "    include_dirs = [ emlearn.common.get_include_dir() ]\n",
    "    test_executable = emlearn.common.compile_executable(\n",
    "            test_source_file,\n",
    "            out_dir,\n",
    "            name=f'test_{name}',\n",
    "            include_dirs=include_dirs\n",
    "    )\n",
    "\n",
    "    import subprocess\n",
    "    errors = None\n",
    "    try:\n",
    "        print(\"TRY\")\n",
    "        subprocess.check_output(test_executable)\n",
    "        errors = 0\n",
    "        print(\"ERROR\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        errors = e.returncode\n",
    "        print(f\"CATCH {e.returncode}\")\n",
    "\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(ax, model, X, y):\n",
    "    from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "    # show classification boundaries\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        model, X, alpha=0.4, ax=ax, response_method=\"auto\",\n",
    "    )\n",
    "\n",
    "    # show datapoints\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, s=20, edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_run_classifier(model, name, X_train, Y_train, X_test, Y_test, feature_columns):\n",
    "    \"\"\"\n",
    "    Treina, avalia, converte e salva um classificador usando emlearn.\n",
    "    \"\"\"\n",
    "    print(f\"Processando o modelo: {name}\")\n",
    "\n",
    "    # Treina o modelo com o conjunto de treinamento\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Avalia a acurácia no conjunto de teste\n",
    "    accuracy = accuracy_score(Y_test, model.predict(X_test))\n",
    "    print(f\"Acurácia do modelo em Python: {accuracy:.4f}\")\n",
    "\n",
    "    # Converte o modelo treinado para código C\n",
    "    inference_strategy = 'loadable'\n",
    "    if type(model).__name__ in emlearn.trees.SUPPORTED_ESTIMATORS:\n",
    "        inference_strategy = 'inline'\n",
    "\n",
    "    cmodel = emlearn.convert(\n",
    "        model,\n",
    "        method=inference_strategy,\n",
    "        dtype='float'\n",
    "    )\n",
    "\n",
    "    # Salva o modelo C em um arquivo .h\n",
    "    out_dir = os.path.join(os.getcwd(), '../data/c_models')\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    model_filename = os.path.join(out_dir, f'{name}_model.h')\n",
    "    \n",
    "    try:\n",
    "        cmodel.save(file=model_filename, name='model')\n",
    "        print(f\"Modelo salvo em: {model_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o modelo {name}: {e}\")\n",
    "\n",
    "    # Verifica a acurácia do modelo convertido\n",
    "    test_data_c = X_test.values.astype(np.float32)\n",
    "    c_predictions = cmodel.predict(test_data_c)\n",
    "    c_accuracy = accuracy_score(Y_test, c_predictions)\n",
    "    print(f\"Acurácia do modelo em C (emlearn): {c_accuracy:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'python_accuracy': accuracy,\n",
    "        'c_accuracy': c_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário com os classificadores para emlearn\n",
    "classifiers_emlearn = {\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=42),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    # 'extra_trees': ExtraTreesClassifier(n_estimators=10, random_state=42),\n",
    "    'gaussian_naive_bayes': GaussianNB(),\n",
    "    'knn' : KNeighborsClassifier(n_neighbors=3),\n",
    "    # 'sklearn_mlp': MLPClassifier(hidden_layer_sizes=(10,10,), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\n--- Treinamento e Conversão dos Modelos para MCU ---\")\n",
    "\n",
    "mcu_results = {}\n",
    "for name, model in classifiers_emlearn.items():\n",
    "    result = build_run_classifier(model, name, X_train, Y_train, X_test, Y_test, feature_columns)\n",
    "    mcu_results[name] = result\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== RESUMO FINAL DAS ACURÁCIAS =====\\n\")\n",
    "print(\"--- Modelos de Desktop (Avaliados com Cross-Validation k=5) ---\")\n",
    "for name, res in results_cv.items():\n",
    "    print(f\"{name:<25} | Acurácia Média: {res['mean_accuracy']:.4f} (std: {res['std_accuracy']:.4f})\")\n",
    "\n",
    "print(\"\\n\\n--- Modelos para MCU (Acurácia no Split de Teste Fixo) ---\")\n",
    "for name, res in mcu_results.items():\n",
    "    print(f\"{name:<25} | Acurácia Python: {res['python_accuracy']:.4f} | Acurácia C (emlearn): {res['c_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto-tg-ZGfju8ng-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
