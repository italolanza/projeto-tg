{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Data Analyser\n",
    "\n",
    "- Notebook que faz a analise dos resultados das features extraidas do microcontrolador e geras os graficos para serem utilizados no relatorio do TG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Ha **15** colunas no arquivo csv dos dados das features:\n",
    "    1. **`RMS`:** \n",
    "    2. **`Variance`:** \n",
    "    3. **`Skewness`:** \n",
    "    4. **`Kurtosis`:** \n",
    "    5. **`CrestFactor`:** \n",
    "    6. **`ShapeFactor`:** \n",
    "    7. **`ImpulseFactor`:** \n",
    "    8. **`MarginFactor`:** \n",
    "    9. **`Peak1`:** \n",
    "    10. **`Peak2`:** \n",
    "    11. **`Peak3`:** \n",
    "    12. **`PeakLocs1`:** \n",
    "    13. **`PeakLocs2`:** \n",
    "    14. **`PeakLocs3`:** \n",
    "    14. **`FAULT_ID`:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Os dados foram extraidos utilizando os modelos: **_Decision Tree_**, **_Extra Tree_**, **_Gaussian Naive Bayess_** e **_Random Forest_**\n",
    "    - Alem disso, para cada modelo foi feito a captura dos dados de tempo para cada um dos arquivos de audio: _Off Condition with noise_, _Healthy condition_, _Bearing fault (F1)_, _Fan fault (F2)_ e _Gear fault (F3)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'DecisionTree': {\n",
    "        'FAULT_ID_OFF': '../data/extracted_features/uControlador/decision_tree/features/DT-F-OFF.CSV',\n",
    "        'FAULT_ID_HEALTH': '../data/extracted_features/uControlador/decision_tree/features/DT-F-HTH.CSV',\n",
    "        'FAULT_ID_BEARING': '../data/extracted_features/uControlador/decision_tree/features/DT-F-F1.CSV',\n",
    "        'FAULT_ID_FAN': '../data/extracted_features/uControlador/decision_tree/features/DT-F-F2.CSV',\n",
    "        'FAULT_ID_GEAR': '../data/extracted_features/uControlador/decision_tree/features/DT-F-F3.CSV',\n",
    "    },\n",
    "    'ExtraTree': {\n",
    "        'FAULT_ID_OFF': '../data/extracted_features/uControlador/extra_trees/features/ET-F-OFF.CSV',\n",
    "        'FAULT_ID_HEALTH': '../data/extracted_features/uControlador/extra_trees/features/ET-F-HTH.CSV',\n",
    "        'FAULT_ID_BEARING': '../data/extracted_features/uControlador/extra_trees/features/ET-F-F1.CSV',\n",
    "        'FAULT_ID_FAN': '../data/extracted_features/uControlador/extra_trees/features/ET-F-F2.CSV',\n",
    "        'FAULT_ID_GEAR': '../data/extracted_features/uControlador/extra_trees/features/ET-F-F3.CSV',\n",
    "    },\n",
    "    'GaussianNaiveBayes': {\n",
    "        'FAULT_ID_OFF': '../data/extracted_features/uControlador/gaussian_naive_bayes/features/NB-F-OFF.CSV',\n",
    "        'FAULT_ID_HEALTH': '../data/extracted_features/uControlador/gaussian_naive_bayes/features/NB-F-HTH.CSV',\n",
    "        'FAULT_ID_BEARING': '../data/extracted_features/uControlador/gaussian_naive_bayes/features/NB-F-F1.CSV',\n",
    "        'FAULT_ID_FAN': '../data/extracted_features/uControlador/gaussian_naive_bayes/features/NB-F-F2.CSV',\n",
    "        'FAULT_ID_GEAR': '../data/extracted_features/uControlador/gaussian_naive_bayes/features/NB-F-F3.CSV',\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'FAULT_ID_OFF': '../data/extracted_features/uControlador/random_forest/features/RF-F-OFF.CSV',\n",
    "        'FAULT_ID_HEALTH': '../data/extracted_features/uControlador/random_forest/features/RF-F-HTH.CSV',\n",
    "        'FAULT_ID_BEARING': '../data/extracted_features/uControlador/random_forest/features/RF-F-F1.CSV',\n",
    "        'FAULT_ID_FAN': '../data/extracted_features/uControlador/random_forest/features/RF-F-F2.CSV',\n",
    "        'FAULT_ID_GEAR': '../data/extracted_features/uControlador/random_forest/features/RF-F-F3.CSV',\n",
    "    },\n",
    "}\n",
    "\n",
    "CONDITION_MAPPING = {\n",
    "    'FAULT_ID_OFF': 1,\n",
    "    'FAULT_ID_HEALTH': 2,\n",
    "    'FAULT_ID_BEARING': 3,\n",
    "    'FAULT_ID_FAN': 4,\n",
    "    'FAULT_ID_GEAR': 5\n",
    "}\n",
    "\n",
    "\n",
    "# SOUND_FILES = [\n",
    "#     '../data/audio_files/off.wav',      # Off Condition with noise ((Fault_ID1))\n",
    "#     '../data/audio_files/health.wav',   # Healthy condition (Fault_ID2)\n",
    "#     '../data/audio_files/f1.wav',       # Bearing fault (Fault_ID3)\n",
    "#     '../data/audio_files/f2.wav',       # Fan fault (Fault_ID4)\n",
    "#     '../data/audio_files/f3.wav'        # Gear fault (Fault_ID5)\n",
    "# ]\n",
    "\n",
    "CSV_COLUMNS_NAMES=['RMS','Variance','Skewness','Kurtosis','CrestFactor','ShapeFactor','ImpulseFactor','MarginFactor','Peak1','Peak2','Peak3','PeakLocs1','PeakLocs2','PeakLocs3','FAULT_ID']\n",
    "\n",
    "AUDIO_SAMPLE_RATE = 48000   # 48kHz, do arquivo de audio .wav\n",
    "INPUT_BUFFER_SIZE = 2048    # Tamanho do buffer usado\n",
    "\n",
    "# Nomes das classes\n",
    "FAULT_LABELS  = ['Off Condition with noise', 'Healthy', 'Bearing fault', 'Gear fault', 'Fan fault']\n",
    "window_size = 20  # Tamanho da janela igual ao usado no artigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(file_path, condition):\n",
    "    \"\"\"\n",
    "    Pre-processa o CSV para ajustar formato e adicionar Fault_ID\n",
    "    \n",
    "    :param file_path: Caminho do arquivo CSV\n",
    "    :param condition: Condição correspondente ao arquivo\n",
    "    :return: DataFrame pré-processado\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Renomear coluna FAULT_ID para Prediction\n",
    "    if 'FAULT_ID' in df.columns:\n",
    "        df.rename(columns={'FAULT_ID': 'Prediction'}, inplace=True)\n",
    "    \n",
    "    # Adicionar coluna Fault_ID baseado na condição\n",
    "    df['Fault_ID'] = CONDITION_MAPPING.get(condition, -1)\n",
    "    \n",
    "    # Verificar mapeamento correto\n",
    "    if df['Fault_ID'].iloc[0] == -1:\n",
    "        raise ValueError(f\"Condição {condition} não encontrada no mapeamento\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ecdf(predictions, window_size=20):\n",
    "    \"\"\"\n",
    "    Aplica Empirical Cumulative Distribution Function em uma janela deslizante\n",
    "    para estabilizar as previsões usando a moda das ultimas 'window_size' amostras\n",
    "    \n",
    "    :param predictions: Array de previsões brutas\n",
    "    :param window_size: Tamanho da janela para cálculo da moda\n",
    "    :return: Array de previsões estabilizadas\n",
    "    \"\"\"\n",
    "    stabilized = []\n",
    "    window = deque(maxlen=window_size)\n",
    "    \n",
    "    for pred in predictions:\n",
    "        window.append(pred)\n",
    "        values, counts = np.unique(list(window), return_counts=True)\n",
    "        stabilized.append(values[np.argmax(counts)])\n",
    "    \n",
    "    return np.array(stabilized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_results(model_name, csv_files, fault_labels, window_size=20):\n",
    "    \"\"\"\n",
    "    Processa resultados com pre-processamento e ECDF\n",
    "    \n",
    "    :param model_name: Nome do modelo para título dos gráficos\n",
    "    :param csv_files: Dicionário com {condição: caminho_arquivo}\n",
    "    :param fault_labels: Lista com nomes das classes/falhas\n",
    "    :param window_size: Tamanho da janela para ECDF\n",
    "    \"\"\"\n",
    "    all_true = []\n",
    "    all_pred_raw = []\n",
    "    \n",
    "    # Processar cada arquivo\n",
    "    for condition, file_path in csv_files.items():\n",
    "        try:\n",
    "            df = preprocess_csv(file_path, condition)\n",
    "            all_true.extend(df['Fault_ID'].values)\n",
    "            all_pred_raw.extend(df['Prediction'].values)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro em {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Aplicar ECDF\n",
    "    all_pred = apply_ecdf(all_pred_raw, window_size)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(all_true, all_pred)\n",
    "    cm = confusion_matrix(all_true, all_pred, normalize='true')\n",
    "    \n",
    "    # Plotar matriz\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap='Blues',\n",
    "                xticklabels=fault_labels, \n",
    "                yticklabels=fault_labels)\n",
    "    plt.title(f'{model_name} - Acurácia: {accuracy:.2%}\\nJanela ECDF={window_size}')\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.savefig(f'../data/{model_name}_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar todos os modelos --------------------------------------------------\n",
    "results = {}\n",
    "for model_name, csv_files in models.items():\n",
    "    try:\n",
    "        acc = process_model_results(\n",
    "            model_name,\n",
    "            csv_files,\n",
    "            FAULT_LABELS,\n",
    "            window_size=100\n",
    "        )\n",
    "        results[model_name] = acc\n",
    "    except Exception as e:\n",
    "        print(f\"Falha no modelo {model_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir resultados\n",
    "print(\"\\nResultados Finais:\")\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: {acc:.2%}\")\n",
    "\n",
    "# Salvar relatório\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['Acurácia']).to_csv('../data/relatorio_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel TG",
   "language": "python",
   "name": "projeto-tg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
