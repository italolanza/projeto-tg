{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Faz o treinamento e avaliacao da acuracia dos classificadores utilizando um arquivo `.csv` gerado pelo notebook `Main.ipynb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv(\"./data_matlab_artigo.csv\")\n",
    "X = data.iloc[:, 0:-1]                # All column except the last one\n",
    "X = X.drop(columns=['Mean', 'Median']) # Remove the mean and median column\n",
    "y = data.iloc[:, -1]                  # Last Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Trees Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/dev/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/dev/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/dev/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/dev/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia em cada fold : [0.98243148 0.97470134 0.9845397  0.97540408 0.97329585]\n",
      "Acurácia média        : 0.9780744905130007\n"
     ]
    }
   ],
   "source": [
    "# Criar o classificador base (uma única árvore de decisão)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Criar o classificador Bagged Trees Ensemble\n",
    "bagged_classifier = BaggingClassifier(base_estimator=base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "bgtree_scores = cross_val_score(bagged_classifier, X, y, cv=skf)\n",
    "\n",
    "print(\"Acurácia em cada fold :\", bgtree_scores)\n",
    "print(\"Acurácia média        :\", bgtree_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia em cada fold : [0.86718201 0.86577653 0.86296557 0.86929023 0.87069571]\n",
      "Acurácia média        : 0.8671820098383696\n"
     ]
    }
   ],
   "source": [
    "# Criar o classificador SVM Quadrático\n",
    "svm_classifier = SVC(kernel='poly',degree=2,C=2)  # degree=2 para o kernel quadrático\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "svm_cv_scores = cross_val_score(svm_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", svm_cv_scores)\n",
    "print(\"Acurácia média        :\", svm_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia em cada fold : [0.96486297 0.97680956 0.96837667 0.97470134 0.96275474]\n",
      "Acurácia média        : 0.9695010541110332\n"
     ]
    }
   ],
   "source": [
    "# Criar o classificador Fine Decision Tree\n",
    "fine_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "fdtree_cv_scores = cross_val_score(fine_tree_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", fdtree_cv_scores)\n",
    "print(\"Acurácia média        :\", fdtree_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia em cada fold : [0.90513001 0.8945889  0.89107519 0.90653549 0.89248067]\n",
      "Acurácia média        : 0.897962052002811\n"
     ]
    }
   ],
   "source": [
    "# Criar o classificador Naïve Bayes\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "nb_cv_scores = cross_val_score(naive_bayes_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", nb_cv_scores)\n",
    "print(\"Acurácia média        :\", nb_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia em cada fold : [0.91075193 0.92761771 0.89669712 0.91496838 0.88826423]\n",
      "Acurácia média        : 0.907659873506676\n"
     ]
    }
   ],
   "source": [
    "# Criar o classificador KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Número de vizinhos = 3 (pode ser ajustado)\n",
    "\n",
    "# # Realizar a validação cruzada com k = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "knn_cv_scores = cross_val_score(knn_classifier, X, y, cv=skf)\n",
    "\n",
    "# Imprimir as acurácias de cada fold e a acurácia média\n",
    "print(\"Acurácia em cada fold :\", knn_cv_scores)\n",
    "print(\"Acurácia média        :\", knn_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Trees Ensemble: 0.9780744905130007\n",
      "Quadratic SVM:         0.8671820098383696\n",
      "Fine Decision Tree :   0.9695010541110332\n",
      "Naïve Bayes :          0.897962052002811\n",
      "KNeighbors (KNN) :     0.907659873506676\n"
     ]
    }
   ],
   "source": [
    "# Resumo\n",
    "print(f\"Bagged Trees Ensemble: {bgtree_scores.mean()}\")\n",
    "print(f\"Quadratic SVM:         {svm_cv_scores.mean()}\")\n",
    "print(f\"Fine Decision Tree :   {fdtree_cv_scores.mean()}\")\n",
    "print(f\"Naïve Bayes :          {nb_cv_scores.mean()}\")\n",
    "print(f\"KNeighbors (KNN) :     {knn_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emlearn\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dev/Workspace/TG/source/test-emlearn/test.h\n",
      "/home/dev/Workspace/TG/source\n"
     ]
    }
   ],
   "source": [
    "# Convert model using emlearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
